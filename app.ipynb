{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt_index import SimpleDirectoryReader, GPTListIndex, GPTSimpleVectorIndex, LLMPredictor, PromptHelper\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "import gradio as gr\n",
    "import sys\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = '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'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_index(directory_path):\n",
    "    max_input_size = 4096\n",
    "    num_outputs = 512\n",
    "    max_chunk_overlap = 20\n",
    "    chunk_size_limit = 600\n",
    "\n",
    "    prompt_helper = PromptHelper(max_input_size, num_outputs, max_chunk_overlap, chunk_size_limit=chunk_size_limit)\n",
    "\n",
    "    llm_predictor = LLMPredictor(llm=ChatOpenAI(temperature=0.7, model_name=\"gpt-3.5-turbo\", max_tokens=num_outputs))\n",
    "\n",
    "    documents = SimpleDirectoryReader(directory_path).load_data()\n",
    "\n",
    "    index = GPTSimpleVectorIndex(documents, llm_predictor=llm_predictor, prompt_helper=prompt_helper)\n",
    "\n",
    "    index.save_to_disk('index.json')\n",
    "\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "RetryError",
     "evalue": "RetryError[<Future at 0x161f189a0 state=finished raised AuthenticationError>]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/thinkmetrics-ai/.venv/lib/python3.9/site-packages/tenacity/__init__.py:382\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 382\u001b[0m     result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    383\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m:  \u001b[39m# noqa: B902\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/thinkmetrics-ai/.venv/lib/python3.9/site-packages/gpt_index/embeddings/openai.py:147\u001b[0m, in \u001b[0;36mget_embeddings\u001b[0;34m(list_of_text, engine)\u001b[0m\n\u001b[1;32m    145\u001b[0m list_of_text \u001b[39m=\u001b[39m [text\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfor\u001b[39;00m text \u001b[39min\u001b[39;00m list_of_text]\n\u001b[0;32m--> 147\u001b[0m data \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mEmbedding\u001b[39m.\u001b[39;49mcreate(\u001b[39minput\u001b[39;49m\u001b[39m=\u001b[39;49mlist_of_text, engine\u001b[39m=\u001b[39;49mengine)\u001b[39m.\u001b[39mdata\n\u001b[1;32m    148\u001b[0m data \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m(data, key\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: x[\u001b[39m\"\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m\"\u001b[39m])  \u001b[39m# maintain the same order as input.\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/thinkmetrics-ai/.venv/lib/python3.9/site-packages/openai/api_resources/embedding.py:33\u001b[0m, in \u001b[0;36mEmbedding.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 33\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     35\u001b[0m     \u001b[39m# If a user specifies base64, we'll just return the encoded string.\u001b[39;00m\n\u001b[1;32m     36\u001b[0m     \u001b[39m# This is only for the default case.\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/thinkmetrics-ai/.venv/lib/python3.9/site-packages/openai/api_resources/abstract/engine_api_resource.py:149\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[1;32m    141\u001b[0m         timeout,\n\u001b[1;32m    142\u001b[0m         stream,\n\u001b[1;32m    143\u001b[0m         headers,\n\u001b[1;32m    144\u001b[0m         request_timeout,\n\u001b[1;32m    145\u001b[0m         typed_api_type,\n\u001b[1;32m    146\u001b[0m         requestor,\n\u001b[1;32m    147\u001b[0m         url,\n\u001b[1;32m    148\u001b[0m         params,\n\u001b[0;32m--> 149\u001b[0m     ) \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m__prepare_create_request(\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[1;32m    153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39mrequest(\n\u001b[1;32m    154\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mpost\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    155\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[1;32m    161\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/thinkmetrics-ai/.venv/lib/python3.9/site-packages/openai/api_resources/abstract/engine_api_resource.py:106\u001b[0m, in \u001b[0;36mEngineAPIResource.__prepare_create_request\u001b[0;34m(cls, api_key, api_base, api_type, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    104\u001b[0m     params[\u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m MAX_TIMEOUT\n\u001b[0;32m--> 106\u001b[0m requestor \u001b[39m=\u001b[39m api_requestor\u001b[39m.\u001b[39;49mAPIRequestor(\n\u001b[1;32m    107\u001b[0m     api_key,\n\u001b[1;32m    108\u001b[0m     api_base\u001b[39m=\u001b[39;49mapi_base,\n\u001b[1;32m    109\u001b[0m     api_type\u001b[39m=\u001b[39;49mapi_type,\n\u001b[1;32m    110\u001b[0m     api_version\u001b[39m=\u001b[39;49mapi_version,\n\u001b[1;32m    111\u001b[0m     organization\u001b[39m=\u001b[39;49morganization,\n\u001b[1;32m    112\u001b[0m )\n\u001b[1;32m    113\u001b[0m url \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mclass_url(engine, api_type, api_version)\n",
      "File \u001b[0;32m~/Documents/thinkmetrics-ai/.venv/lib/python3.9/site-packages/openai/api_requestor.py:138\u001b[0m, in \u001b[0;36mAPIRequestor.__init__\u001b[0;34m(self, key, api_base, api_type, api_version, organization)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_base \u001b[39m=\u001b[39m api_base \u001b[39mor\u001b[39;00m openai\u001b[39m.\u001b[39mapi_base\n\u001b[0;32m--> 138\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key \u001b[39m=\u001b[39m key \u001b[39mor\u001b[39;00m util\u001b[39m.\u001b[39;49mdefault_api_key()\n\u001b[1;32m    139\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_type \u001b[39m=\u001b[39m (\n\u001b[1;32m    140\u001b[0m     ApiType\u001b[39m.\u001b[39mfrom_str(api_type)\n\u001b[1;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m api_type\n\u001b[1;32m    142\u001b[0m     \u001b[39melse\u001b[39;00m ApiType\u001b[39m.\u001b[39mfrom_str(openai\u001b[39m.\u001b[39mapi_type)\n\u001b[1;32m    143\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/thinkmetrics-ai/.venv/lib/python3.9/site-packages/openai/util.py:186\u001b[0m, in \u001b[0;36mdefault_api_key\u001b[0;34m()\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 186\u001b[0m     \u001b[39mraise\u001b[39;00m openai\u001b[39m.\u001b[39merror\u001b[39m.\u001b[39mAuthenticationError(\n\u001b[1;32m    187\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo API key provided. You can set your API key in code using \u001b[39m\u001b[39m'\u001b[39m\u001b[39mopenai.api_key = <API-KEY>\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with \u001b[39m\u001b[39m'\u001b[39m\u001b[39mopenai.api_key_path = <PATH>\u001b[39m\u001b[39m'\u001b[39m\u001b[39m. You can generate API keys in the OpenAI web interface. See https://platform.openai.com/account/api-keys for details.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    188\u001b[0m     )\n",
      "\u001b[0;31mAuthenticationError\u001b[0m: No API key provided. You can set your API key in code using 'openai.api_key = <API-KEY>', or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with 'openai.api_key_path = <PATH>'. You can generate API keys in the OpenAI web interface. See https://platform.openai.com/account/api-keys for details.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRetryError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 12\u001b[0m\n\u001b[1;32m      6\u001b[0m iface \u001b[39m=\u001b[39m gr\u001b[39m.\u001b[39mInterface(fn\u001b[39m=\u001b[39mchatbot,\n\u001b[1;32m      7\u001b[0m                      inputs\u001b[39m=\u001b[39mgr\u001b[39m.\u001b[39mcomponents\u001b[39m.\u001b[39mTextbox(lines\u001b[39m=\u001b[39m\u001b[39m7\u001b[39m, label\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEnter your text\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m      8\u001b[0m                      outputs\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      9\u001b[0m                      title\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCustom-trained AI Chatbot\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m directory_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/Users/kaushals/Documents/thinkmetrics-ai/cheatsheetbot\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m---> 12\u001b[0m index \u001b[39m=\u001b[39m construct_index(directory_path)\n\u001b[1;32m     13\u001b[0m iface\u001b[39m.\u001b[39mlaunch(share\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[18], line 13\u001b[0m, in \u001b[0;36mconstruct_index\u001b[0;34m(directory_path)\u001b[0m\n\u001b[1;32m      9\u001b[0m llm_predictor \u001b[39m=\u001b[39m LLMPredictor(llm\u001b[39m=\u001b[39mChatOpenAI(temperature\u001b[39m=\u001b[39m\u001b[39m0.7\u001b[39m, model_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgpt-3.5-turbo\u001b[39m\u001b[39m\"\u001b[39m, max_tokens\u001b[39m=\u001b[39mnum_outputs))\n\u001b[1;32m     11\u001b[0m documents \u001b[39m=\u001b[39m SimpleDirectoryReader(directory_path)\u001b[39m.\u001b[39mload_data()\n\u001b[0;32m---> 13\u001b[0m index \u001b[39m=\u001b[39m GPTSimpleVectorIndex(documents, llm_predictor\u001b[39m=\u001b[39;49mllm_predictor, prompt_helper\u001b[39m=\u001b[39;49mprompt_helper)\n\u001b[1;32m     15\u001b[0m index\u001b[39m.\u001b[39msave_to_disk(\u001b[39m'\u001b[39m\u001b[39mindex.json\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[39mreturn\u001b[39;00m index\n",
      "File \u001b[0;32m~/Documents/thinkmetrics-ai/.venv/lib/python3.9/site-packages/gpt_index/indices/vector_store/vector_indices.py:84\u001b[0m, in \u001b[0;36mGPTSimpleVectorIndex.__init__\u001b[0;34m(self, documents, index_struct, text_qa_template, llm_predictor, embed_model, simple_vector_store_data_dict, **kwargs)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Init params.\"\"\"\u001b[39;00m\n\u001b[1;32m     80\u001b[0m vector_store \u001b[39m=\u001b[39m SimpleVectorStore(\n\u001b[1;32m     81\u001b[0m     simple_vector_store_data_dict\u001b[39m=\u001b[39msimple_vector_store_data_dict\n\u001b[1;32m     82\u001b[0m )\n\u001b[0;32m---> 84\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[1;32m     85\u001b[0m     documents\u001b[39m=\u001b[39;49mdocuments,\n\u001b[1;32m     86\u001b[0m     index_struct\u001b[39m=\u001b[39;49mindex_struct,\n\u001b[1;32m     87\u001b[0m     text_qa_template\u001b[39m=\u001b[39;49mtext_qa_template,\n\u001b[1;32m     88\u001b[0m     llm_predictor\u001b[39m=\u001b[39;49mllm_predictor,\n\u001b[1;32m     89\u001b[0m     embed_model\u001b[39m=\u001b[39;49membed_model,\n\u001b[1;32m     90\u001b[0m     vector_store\u001b[39m=\u001b[39;49mvector_store,\n\u001b[1;32m     91\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m     92\u001b[0m )\n\u001b[1;32m     94\u001b[0m \u001b[39m# TODO: Temporary hack to also store embeddings in index_struct\u001b[39;00m\n\u001b[1;32m     95\u001b[0m embedding_dict \u001b[39m=\u001b[39m vector_store\u001b[39m.\u001b[39m_data\u001b[39m.\u001b[39membedding_dict\n",
      "File \u001b[0;32m~/Documents/thinkmetrics-ai/.venv/lib/python3.9/site-packages/gpt_index/indices/vector_store/base.py:63\u001b[0m, in \u001b[0;36mGPTVectorStoreIndex.__init__\u001b[0;34m(self, documents, index_struct, text_qa_template, llm_predictor, embed_model, vector_store, text_splitter, use_async, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtext_qa_template \u001b[39m=\u001b[39m text_qa_template \u001b[39mor\u001b[39;00m DEFAULT_TEXT_QA_PROMPT\n\u001b[1;32m     62\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_use_async \u001b[39m=\u001b[39m use_async\n\u001b[0;32m---> 63\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[1;32m     64\u001b[0m     documents\u001b[39m=\u001b[39;49mdocuments,\n\u001b[1;32m     65\u001b[0m     index_struct\u001b[39m=\u001b[39;49mindex_struct,\n\u001b[1;32m     66\u001b[0m     llm_predictor\u001b[39m=\u001b[39;49mllm_predictor,\n\u001b[1;32m     67\u001b[0m     embed_model\u001b[39m=\u001b[39;49membed_model,\n\u001b[1;32m     68\u001b[0m     text_splitter\u001b[39m=\u001b[39;49mtext_splitter,\n\u001b[1;32m     69\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m     70\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/thinkmetrics-ai/.venv/lib/python3.9/site-packages/gpt_index/indices/base.py:109\u001b[0m, in \u001b[0;36mBaseGPTIndex.__init__\u001b[0;34m(self, documents, index_struct, llm_predictor, embed_model, docstore, index_registry, prompt_helper, text_splitter, chunk_size_limit, include_extra_info)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_documents(documents)\n\u001b[1;32m    108\u001b[0m     \u001b[39m# TODO: introduce document store outside __init__ function\u001b[39;00m\n\u001b[0;32m--> 109\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_struct \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbuild_index_from_documents(documents)\n\u001b[1;32m    110\u001b[0m \u001b[39m# update index registry and docstore with index_struct\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_index_registry_and_docstore()\n",
      "File \u001b[0;32m~/Documents/thinkmetrics-ai/.venv/lib/python3.9/site-packages/gpt_index/token_counter/token_counter.py:55\u001b[0m, in \u001b[0;36mllm_token_counter.<locals>.wrap.<locals>.wrapped_llm_predict\u001b[0;34m(_self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     52\u001b[0m start_token_ct \u001b[39m=\u001b[39m llm_predictor\u001b[39m.\u001b[39mtotal_tokens_used\n\u001b[1;32m     53\u001b[0m start_embed_token_ct \u001b[39m=\u001b[39m embed_model\u001b[39m.\u001b[39mtotal_tokens_used\n\u001b[0;32m---> 55\u001b[0m f_return_val \u001b[39m=\u001b[39m f(_self, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     57\u001b[0m net_tokens \u001b[39m=\u001b[39m llm_predictor\u001b[39m.\u001b[39mtotal_tokens_used \u001b[39m-\u001b[39m start_token_ct\n\u001b[1;32m     58\u001b[0m llm_predictor\u001b[39m.\u001b[39mlast_token_usage \u001b[39m=\u001b[39m net_tokens\n",
      "File \u001b[0;32m~/Documents/thinkmetrics-ai/.venv/lib/python3.9/site-packages/gpt_index/indices/base.py:278\u001b[0m, in \u001b[0;36mBaseGPTIndex.build_index_from_documents\u001b[0;34m(self, documents)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[39m@llm_token_counter\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mbuild_index_from_documents\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    276\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbuild_index_from_documents\u001b[39m(\u001b[39mself\u001b[39m, documents: Sequence[BaseDocument]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m IS:\n\u001b[1;32m    277\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Build the index from documents.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 278\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_build_index_from_documents(documents)\n",
      "File \u001b[0;32m~/Documents/thinkmetrics-ai/.venv/lib/python3.9/site-packages/gpt_index/indices/vector_store/base.py:206\u001b[0m, in \u001b[0;36mGPTVectorStoreIndex._build_index_from_documents\u001b[0;34m(self, documents)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    205\u001b[0m     \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m documents:\n\u001b[0;32m--> 206\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_add_document_to_index(index_struct, d)\n\u001b[1;32m    207\u001b[0m \u001b[39mreturn\u001b[39;00m index_struct\n",
      "File \u001b[0;32m~/Documents/thinkmetrics-ai/.venv/lib/python3.9/site-packages/gpt_index/indices/vector_store/base.py:182\u001b[0m, in \u001b[0;36mGPTVectorStoreIndex._add_document_to_index\u001b[0;34m(self, index_struct, document)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Add document to index.\"\"\"\u001b[39;00m\n\u001b[1;32m    181\u001b[0m nodes \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_nodes_from_document(document)\n\u001b[0;32m--> 182\u001b[0m embedding_results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_node_embedding_results(\n\u001b[1;32m    183\u001b[0m     nodes, \u001b[39mset\u001b[39;49m(), document\u001b[39m.\u001b[39;49mget_doc_id()\n\u001b[1;32m    184\u001b[0m )\n\u001b[1;32m    186\u001b[0m new_ids \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_vector_store\u001b[39m.\u001b[39madd(embedding_results)\n\u001b[1;32m    188\u001b[0m \u001b[39m# if the vector store doesn't store text, we need to add the nodes to the\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[39m# index struct\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/thinkmetrics-ai/.venv/lib/python3.9/site-packages/gpt_index/indices/vector_store/base.py:102\u001b[0m, in \u001b[0;36mGPTVectorStoreIndex._get_node_embedding_results\u001b[0;34m(self, nodes, existing_node_ids, doc_id)\u001b[0m\n\u001b[1;32m     99\u001b[0m     id_to_node_map[new_id] \u001b[39m=\u001b[39m n\n\u001b[1;32m    101\u001b[0m \u001b[39m# call embedding model to get embeddings\u001b[39;00m\n\u001b[0;32m--> 102\u001b[0m result_ids, result_embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_embed_model\u001b[39m.\u001b[39;49mget_queued_text_embeddings()\n\u001b[1;32m    103\u001b[0m \u001b[39mfor\u001b[39;00m new_id, text_embedding \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(result_ids, result_embeddings):\n\u001b[1;32m    104\u001b[0m     id_to_embed_map[new_id] \u001b[39m=\u001b[39m text_embedding\n",
      "File \u001b[0;32m~/Documents/thinkmetrics-ai/.venv/lib/python3.9/site-packages/gpt_index/embeddings/base.py:151\u001b[0m, in \u001b[0;36mBaseEmbedding.get_queued_text_embeddings\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    149\u001b[0m cur_batch_ids \u001b[39m=\u001b[39m [text_id \u001b[39mfor\u001b[39;00m text_id, _ \u001b[39min\u001b[39;00m cur_batch]\n\u001b[1;32m    150\u001b[0m cur_batch_texts \u001b[39m=\u001b[39m [text \u001b[39mfor\u001b[39;00m _, text \u001b[39min\u001b[39;00m cur_batch]\n\u001b[0;32m--> 151\u001b[0m embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_text_embeddings(cur_batch_texts)\n\u001b[1;32m    152\u001b[0m result_ids\u001b[39m.\u001b[39mextend(cur_batch_ids)\n\u001b[1;32m    153\u001b[0m result_embeddings\u001b[39m.\u001b[39mextend(embeddings)\n",
      "File \u001b[0;32m~/Documents/thinkmetrics-ai/.venv/lib/python3.9/site-packages/gpt_index/embeddings/openai.py:260\u001b[0m, in \u001b[0;36mOpenAIEmbedding._get_text_embeddings\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid mode, model combination: \u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    259\u001b[0m     engine \u001b[39m=\u001b[39m _TEXT_MODE_MODEL_DICT[key]\n\u001b[0;32m--> 260\u001b[0m embeddings \u001b[39m=\u001b[39m get_embeddings(texts, engine\u001b[39m=\u001b[39;49mengine)\n\u001b[1;32m    261\u001b[0m \u001b[39mreturn\u001b[39;00m embeddings\n",
      "File \u001b[0;32m~/Documents/thinkmetrics-ai/.venv/lib/python3.9/site-packages/tenacity/__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[1;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_f\u001b[39m(\u001b[39m*\u001b[39margs: t\u001b[39m.\u001b[39mAny, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: t\u001b[39m.\u001b[39mAny) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mAny:\n\u001b[0;32m--> 289\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(f, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[0;32m~/Documents/thinkmetrics-ai/.venv/lib/python3.9/site-packages/tenacity/__init__.py:379\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m retry_state \u001b[39m=\u001b[39m RetryCallState(retry_object\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, fn\u001b[39m=\u001b[39mfn, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[1;32m    378\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 379\u001b[0m     do \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miter(retry_state\u001b[39m=\u001b[39;49mretry_state)\n\u001b[1;32m    380\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/thinkmetrics-ai/.venv/lib/python3.9/site-packages/tenacity/__init__.py:326\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreraise:\n\u001b[1;32m    325\u001b[0m         \u001b[39mraise\u001b[39;00m retry_exc\u001b[39m.\u001b[39mreraise()\n\u001b[0;32m--> 326\u001b[0m     \u001b[39mraise\u001b[39;00m retry_exc \u001b[39mfrom\u001b[39;00m \u001b[39mfut\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexception\u001b[39;00m()\n\u001b[1;32m    328\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwait:\n\u001b[1;32m    329\u001b[0m     sleep \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwait(retry_state)\n",
      "\u001b[0;31mRetryError\u001b[0m: RetryError[<Future at 0x161f189a0 state=finished raised AuthenticationError>]"
     ]
    }
   ],
   "source": [
    "def chatbot(input_text):\n",
    "    index = GPTSimpleVectorIndex.load_from_disk('index.json')\n",
    "    response = index.query(input_text, response_mode=\"compact\")\n",
    "    return response.response\n",
    "\n",
    "iface = gr.Interface(fn=chatbot,\n",
    "                     inputs=gr.components.Textbox(lines=7, label=\"Enter your text\"),\n",
    "                     outputs=\"text\",\n",
    "                     title=\"Custom-trained AI Chatbot\")\n",
    "\n",
    "directory_path = '/Users/kaushals/Documents/thinkmetrics-ai/cheatsheetbot'\n",
    "index = construct_index(directory_path)\n",
    "iface.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
